# Teorica 1

## Complejidad computacional: Las reglas del juego

- En el contexto de la teoria de complejidad computacional, llamamos **problema** a la descripcion de los datos de entrada y la respuesta a proporcionar para cada dato de entrada.

- Una **instancia** de un problema es un juego valido de datos de entrada.

- Ejemplos:

    1. **Entrada**: Un numero _n_ entero no negativo
    2. **Salida**: El numero _n_ es primo?

- Suponemos una <span style="color:red"> Maquina RAM </span> (_random access memory_)

    1. La memoria esta dada por una sucesion de celdas numeradas, Cada celda puede almacenar un valor _b_ de bits.

    2. Supondremos habitualmente que el tama√±o _b_ de bits de cada celda esta fijo, y suponemos que todos los datos individuales que maneja el algoritmo se pueden almacenar con _b_ bits.

    3. Se tiene un <span style="color:red"> programa imperativo </span> no almacenado en memoria, compuesto por asignaciones y las estructuras de control habituales.

    4. Las asignaciones pueden acceder a celdas de memoria y realizar las operaciones estandar sobre los <span style="color:red"> tipos de datos primitivos </span> habituales.

- Cada instruccion tiene un **tiempo de ejecucion** asociado.

    1. El acceso a cualquier celda de memoria, tanto para lectura como para escritura, es $O(1)$

    2. Las asignaciones y el manejo de las estructuras de control se realiza en $O(1)$

    3. Las operaciones entre valores logicos son $O(1)$.

- Las operaciones entre enteros/reales dependen de _b_:

    1. Las sumas y restas son $O(b)$
    2. Las multiplicaciones y divisiones son $O(b \log b)$

    $\rightarrow$ Si _b_ esta fijo estas operaciones son $O(1)$. En cambio, si no se puede suponer esto, entonces hay que contemplar que el costo de estas operaciones depende de _b_.

- **Tiempo de ejecucion de un algoritmo _A_**:

    $T_A(I) = $ suma de los tiempos de ejecucion de las instrucciones realizadas por el algoritmo con la instancia _I_.

- Dada una instancia _I_, definimos |_I_| como la cantidad de bits necesarios para almacenar los datos de entrada de _I_.

    1. Si _b_ esta fijo y la entrada ocupa _n_ celdas de memoria, entonces **$|I| = bn = O(n)$**

- **Complejidad de un algoritmo _A_**:

    $$f_A(n) = \max_{I:|I|=n} T_A(I)$$

## Notacion O

Dadas dos funciones $f,g : \N \rightarrow \R$, decimos que:

- $f(n) = O(g(n))$ si existen $c\in \R_+$ y $n_0 \in \N$ tales que $f(n) \leq c*g(n)$ para todo $n \geq n_0$

- $f(n) = \Omega(g(n))$ si existen $c\in \R_+$ y $n_0 \in \N$ tales que $f(n) \geq c*g(n)$ para todo $n \geq n_0$

- $f(n) = \Theta(g(n))$ si $f = O(g(n))$ y $f = \Omega(g(n))$

- Si un algoritmo es $O(n)$, se dice <span style="color:red"> lineal </span>

- Si un algoritmo es $O(n^2)$, se dice <span style="color:red"> cuadratico </span>

- Si un algoritmo es $O(n^3)$, se dice <span style="color:red"> cubico </span>

- Si un algoritmo es $O(n^k)$, se dice <span style="color:red"> polinomial </span>

- Si un algoritmo es $O(\log n)$, se dice <span style="color:red"> logaritmico </span>

- Si un algoritmo es $O(d^n)$, se dice <span style="color:red"> exponencial </span>

Cualquier funcion exponencial es peor que cualquier funcion polinomial:
Si $k \in \R_{>1}$ y $d \in \N$ entonces $k^n$ no es $O(n^d)$

La funcion logaritmica es _mejor_ que la funcion lineal (no importa la base), es decir $\log n$ es $O(n)$ pero no a la inversa

## Problemas bien resueltos

## Problemas de optimizacion

## Problemas de optimizacion combinatoria

## Algortimos de fuerza bruta

## Ejemplo: El problema de la mochila

## Backtracking

## Backtracking: Todas las soluciones

## Backtracking - Resolver un _sudoku_

## Fuerza bruta - Problema de las $n$ damas
